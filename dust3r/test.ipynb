{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be655bb9-2162-471f-b147-89f64400efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "source_directory = \"/home/sarah/dust3r\" # have both legged_gym and unitree_sdk\n",
    "# print(\"Getting Policy Cofig from: \", os.path.dirname(os.path.realpath(__file__)))\n",
    "\n",
    "# adding the parent directory to the sys.path.\n",
    "sys.path.append(source_directory)\n",
    "\n",
    "from dust3r.inference import inference, load_model\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    model_path = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "    device = 'cuda'\n",
    "    batch_size = 1\n",
    "    schedule = 'cosine'\n",
    "    lr = 0.01\n",
    "    niter = 300\n",
    "\n",
    "    model = load_model(model_path, device)\n",
    "    # load_images can take a list of images or a directory\n",
    "    images = load_images(['croco/assets/Chateau1.png', 'croco/assets/Chateau2.png'], size=512)\n",
    "    pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "    output = inference(pairs, model, device, batch_size=batch_size)\n",
    "\n",
    "    # at this stage, you have the raw dust3r predictions\n",
    "    view1, pred1 = output['view1'], output['pred1']\n",
    "    view2, pred2 = output['view2'], output['pred2']\n",
    "    # here, view1, pred1, view2, pred2 are dicts of lists of len(2)\n",
    "    #  -> because we symmetrize we have (im1, im2) and (im2, im1) pairs\n",
    "    # in each view you have:\n",
    "    # an integer image identifier: view1['idx'] and view2['idx']\n",
    "    # the img: view1['img'] and view2['img']\n",
    "    # the image shape: view1['true_shape'] and view2['true_shape']\n",
    "    # an instance string output by the dataloader: view1['instance'] and view2['instance']\n",
    "    # pred1 and pred2 contains the confidence values: pred1['conf'] and pred2['conf']\n",
    "    # pred1 contains 3D points for view1['img'] in view1['img'] space: pred1['pts3d']\n",
    "    # pred2 contains 3D points for view2['img'] in view1['img'] space: pred2['pts3d_in_other_view']\n",
    "\n",
    "    # next we'll use the global_aligner to align the predictions\n",
    "    # depending on your task, you may be fine with the raw output and not need it\n",
    "    # with only two input images, you could use GlobalAlignerMode.PairViewer: it would just convert the output\n",
    "    # if using GlobalAlignerMode.PairViewer, no need to run compute_global_alignment\n",
    "    scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "    loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "    # retrieve useful values from scene:\n",
    "    imgs = scene.imgs\n",
    "    focals = scene.get_focals()\n",
    "    poses = scene.get_im_poses()\n",
    "    pts3d = scene.get_pts3d()\n",
    "    confidence_masks = scene.get_masks()\n",
    "\n",
    "    # visualize reconstruction\n",
    "    scene.show()\n",
    "\n",
    "    # find 2D-2D matches between the two images\n",
    "    from dust3r.utils.geometry import find_reciprocal_matches, xy_grid\n",
    "    pts2d_list, pts3d_list = [], []\n",
    "    for i in range(2):\n",
    "        conf_i = confidence_masks[i].cpu().numpy()\n",
    "        pts2d_list.append(xy_grid(*imgs[i].shape[:2][::-1])[conf_i])  # imgs[i].shape[:2] = (H, W)\n",
    "        pts3d_list.append(pts3d[i].detach().cpu().numpy()[conf_i])\n",
    "    reciprocal_in_P2, nn2_in_P1, num_matches = find_reciprocal_matches(*pts3d_list)\n",
    "    print(f'found {num_matches} matches')\n",
    "    matches_im1 = pts2d_list[1][reciprocal_in_P2]\n",
    "    matches_im0 = pts2d_list[0][nn2_in_P1][reciprocal_in_P2]\n",
    "\n",
    "    # visualize a few matches\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as pl\n",
    "    n_viz = 10\n",
    "    match_idx_to_viz = np.round(np.linspace(0, num_matches-1, n_viz)).astype(int)\n",
    "    viz_matches_im0, viz_matches_im1 = matches_im0[match_idx_to_viz], matches_im1[match_idx_to_viz]\n",
    "\n",
    "    H0, W0, H1, W1 = *imgs[0].shape[:2], *imgs[1].shape[:2]\n",
    "    img0 = np.pad(imgs[0], ((0, max(H1 - H0, 0)), (0, 0), (0, 0)), 'constant', constant_values=0)\n",
    "    img1 = np.pad(imgs[1], ((0, max(H0 - H1, 0)), (0, 0), (0, 0)), 'constant', constant_values=0)\n",
    "    img = np.concatenate((img0, img1), axis=1)\n",
    "    pl.figure()\n",
    "    pl.imshow(img)\n",
    "    cmap = pl.get_cmap('jet')\n",
    "    for i in range(n_viz):\n",
    "        (x0, y0), (x1, y1) = viz_matches_im0[i].T, viz_matches_im1[i].T\n",
    "        pl.plot([x0, x1 + W0], [y0, y1], '-+', color=cmap(i / (n_viz - 1)), scalex=False, scaley=False)\n",
    "    pl.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f11fe6-a3f8-48e8-b025-454432de21f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PYTHONPATH%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739faa41-493d-455e-a271-5ff2a75ac4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
